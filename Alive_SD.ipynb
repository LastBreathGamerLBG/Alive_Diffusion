{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awCuryerI_IA"
      },
      "source": [
        "# ***Stable Diffusion 1.5***                                                          \n",
        "**\" Diffusion is still alive in Colab \" -LBG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpZ7n9WW59RO"
      },
      "source": [
        "# **Dependancies takes a while to setup dont panic just relaxüòä**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q4HnCko_hrk"
      },
      "outputs": [],
      "source": [
        "# Skip if its your second time using Sd from Alive_Sd.ipynb\n",
        "\n",
        "!pip install transformers diffusers accelerate\n",
        "!pip install xformers # for memory management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEg4Bdfa5erP"
      },
      "source": [
        "# **For Text to Image gernation üó®Ô∏è_üì∑**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7eOMt71KC9m"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You can change \"model_id\" for your custom model just search on google your\n",
        "model name  with last word \"hugging face\". copy model \"model_id\" from  huggingface site given example\n",
        "code.\n",
        "\n",
        "'''\n",
        "\n",
        "from  diffusers import AutoPipelineForText2Image  # importing text to img pipeline\n",
        "from google.colab import files   #some other imports (usefull)\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as render\n",
        "\n",
        "model_id = \"emilianJR/epiCRealism\"     # from huggingface sample code (Model)\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "\n",
        "        # for gpu ‚¨áÔ∏è\n",
        "        model_id, torch_dtype=torch.float16, use_safetensors=True, safety_checker = None, requires_safety_checker = False\n",
        "\n",
        "        # for cpu ‚¨áÔ∏è\n",
        "        # model_id, use_safetensors=True, safety_checker = None, requires_safety_checker = False\n",
        ")\n",
        "\n",
        "\n",
        "# efficent only for gpu ‚¨áÔ∏è\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "pipe = pipe.to(\"cuda\") # set \"cpu\" for cpu and \"cuda\" for gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtAGs1Mv6Uv0"
      },
      "source": [
        "# **Enter Positive and Negative Prompts Here ‚¨áÔ∏è**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PwNrQYwK4uD"
      },
      "outputs": [],
      "source": [
        "# NOTE: NSFW filter is off by defult be alert !!!\n",
        "\n",
        "prompts = \"dog sitting on (bed)++\"\n",
        "negative = \"blurry, bad_quality, worst_quality, bad_anotomy, extra_fingures, low_resolution\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on3bV45O6qIk"
      },
      "source": [
        "# **Image Gernation With Custom Properties ‚ò∏Ô∏èüõû**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvgmxVLwLrTR"
      },
      "outputs": [],
      "source": [
        "image = pipe(\n",
        "\n",
        "             prompt = prompts,\n",
        "             negative_prompt = negative,\n",
        "\n",
        "             # you can change the below properties as per your wish ‚¨áÔ∏è‚¨áÔ∏è\n",
        "\n",
        "             guidance_scale=7,         # how much image will close to prompt.\n",
        "             num_inference_steps=50,   # higher value more quality but slow image gernations.\n",
        "             height=720,\n",
        "             weight=512,               # defult 512x512, for sdxl use 1024x1024\n",
        "\n",
        "            ).images[0]\n",
        "\n",
        "# code for showing and downloading gernated image.\n",
        "imgName = f'{prompts}{random.randint(0,9999)}.png'\n",
        "image = image.save(imgName)\n",
        "output = render.imread(imgName)\n",
        "plt.imshow(output)\n",
        "plt.axis('off')         # to hide the graph axis (x & y)\n",
        "plt.show()              # render img\n",
        "\n",
        "usr = str(input(\"Download Image TYPE YES: \"))\n",
        "usr.lower()\n",
        "if usr == \"yes\":\n",
        "  files.download(imgName)\n",
        "else:\n",
        "  print(f\"image is saved in /content/{imgName}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lt3_Vza7GLIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Api**"
      ],
      "metadata": {
        "id": "StJm3UrU1iHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask\n",
        "!pip install pyngrok\n",
        "\n",
        "from flask import Flask, request, jsonify, send_from_directory\n",
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "import random\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Authenticate ngrok with your authtoken\n",
        "ngrok_auth_token = \"Your Ngrok Token HERE !\"  # Replace with your actual ngrok authtoken\n",
        "ngrok.set_auth_token(ngrok_auth_token)\n",
        "\n",
        "# Initialize the image generation pipeline\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "    \"emilianJR/epiCRealism\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False\n",
        ")\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "pipe = pipe.to(\"cuda\")  # Use GPU\n",
        "\n",
        "# Flask app setup\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Folder to save generated images\n",
        "output_folder = '/content/generated_images'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Create a single ngrok tunnel when the app starts (do not call it inside the route)\n",
        "ngrok.kill()  # Kill any previous tunnels\n",
        "public_url = ngrok.connect(5000)  # This starts only one tunnel\n",
        "print(f\"Public URL for Flask app: {public_url}\")\n",
        "\n",
        "# This route should accept POST requests\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate_image():\n",
        "    # Receive the prompt and negative prompt from WebUI\n",
        "    data = request.get_json()\n",
        "    prompt = data.get(\"prompt\", \"\")\n",
        "    negative_prompt = data.get(\"negative_prompt\", \"\")\n",
        "\n",
        "    # Generate the image\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        guidance_scale=7,\n",
        "        num_inference_steps=50,\n",
        "        height=720,\n",
        "        width=512\n",
        "    ).images[0]\n",
        "\n",
        "    # Save the generated image\n",
        "    img_name = f\"{prompt.replace(' ', '_')}_{random.randint(0, 9999)}.png\"\n",
        "    img_path = os.path.join(output_folder, img_name)\n",
        "    image.save(img_path)\n",
        "\n",
        "    # Return only the image file name (not the full ngrok URL)\n",
        "    return jsonify({\"image_name\": img_name})\n",
        "\n",
        "# Serve generated images dynamically\n",
        "@app.route('/generated_images/<filename>')\n",
        "def serve_image(filename):\n",
        "    return send_from_directory(output_folder, filename)\n",
        "\n",
        "# Start the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000, host='0.0.0.0')\n"
      ],
      "metadata": {
        "id": "y96RxqFT1q4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLkTFUu5I_IF"
      },
      "source": [
        "# **More Information Here -:**\n",
        "\n",
        "\n",
        "--> For further learning Stable Diffusion via code here you can Start from:\n",
        "\n",
        "https://huggingface.co/docs/diffusers/en/using-diffusers/conditional_image_generation\n",
        "\n",
        "\n",
        "**Future Updates:**\n",
        "\n",
        "--> Stable Diffusion XL\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "--> Img to Img\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "--> Inpainting\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "--> MaskEditor for Inpainting\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "--> Loars\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "--> Face Warps\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "--> Control Net\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "***VERSION 1.0***"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "sEg4Bdfa5erP",
        "XtAGs1Mv6Uv0",
        "on3bV45O6qIk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
